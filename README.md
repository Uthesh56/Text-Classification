# Text Classification Task

## Overview

Welcome to the KAIBURR Text Classification Task! This project showcases the power of text classification using the Consumer Complaint Dataset. Our primary aim is to categorize consumer complaints into distinct product categories. To accomplish this, we've harnessed the capabilities of four cutting-edge machine learning models:

1. **Multinomial Naive Bayes**
   - Model Type: Multinomial Naive Bayes
   - Description: Leveraging the Naive Bayes algorithm, this model excels in text classification.
   - Performance: Achieved an accuracy of 53.55%.

2. **Logistic Regression**
   - Model Type: Logistic Regression
   - Description: Known for its simplicity and interpretability, Logistic Regression is a powerful linear classification algorithm.
   - Performance: Impressive accuracy of 61.30%.

3. **Random Forest Classifier**
   - Model Type: Random Forest Classifier
   - Description: Harnessing the strength of ensemble learning, this model combines multiple decision trees for predictions.
   - Performance: Delivered an accuracy rate of 60.30%.

4. **Linear Support Vector Classifier (Linear SVC)**
   - Model Type: Linear Support Vector Classifier
   - Description: Tailored for linearly separable data, Linear SVC is a robust Support Vector Machine variant.
   - Performance: Stood out with a remarkable accuracy of 61.875%.

## Getting Started

### Prerequisites

Before diving into this exciting project, ensure you have the following prerequisites in place:

- **Python** (version 3.7 or higher)
- **Jupyter Notebook** (optional but highly recommended)

## Dataset

Our dataset originates from the Consumer Complaint Database, a repository of complaints about consumer financial products and services. These complaints are submitted to companies for responses and become public after the company's confirmation or after 15 days, whichever comes first. The dataset updates regularly, ensuring we work with the most current data. [Source](https://catalog.data.gov/dataset/consumer-complaint-database)

## Usage

To engage with this project and explore its potential, follow the detailed instructions provided in the Jupyter Notebook files for each model. You're encouraged to experiment with various preprocessing techniques, hyperparameter tuning, and feature engineering to further enhance model performance.

## Conclusion

- In the world of text classification, model selection is not a one-size-fits-all proposition. While Linear SVC stood out with the highest accuracy, it's important to remember that the choice of the best model depends on the specific needs and goals of your text classification task. Factors like model interpretability, training time, and scalability must also be weighed in the decision-making process.

- We've gone beyond accuracy to scrutinize precision, recall, and F1-score, providing a more comprehensive performance evaluation. This holistic approach proves crucial when dealing with imbalanced datasets or when certain classes carry greater significance.

- Furthermore, we've highlighted the immense potential for optimization through hyperparameter tuning and feature engineering. By experimenting with different configurations and data preprocessing techniques, you can unlock the full capabilities of each model.

- The journey doesn't conclude with model selection; it's an ongoing process of monitoring and adapting as new data flows in. This ensures that your models remain accurate and aligned with the ever-evolving requirements of your text classification task.

